# On the combined effect of class imbalance and concept complexity in deep learning
Authors: Kushankur Ghosh, Colin Bellinger, Roberto Corizzo, Bartosz Krawczyk, and Nathalie Japkowicz

Published in IEEEBigData'2022

## Abstract
Structural concept complexity, class overlap, and data scarcity are some of the most important factors influencing the performance of classifiers under class imbalance conditions. When these effects were uncovered in the early 2000s, understandably, the classifiers on which they were demonstrated belonged to the classical rather than Deep Learning categories of approaches. As Deep Learning is gaining ground over classical machine learning and is beginning to be used in critical applied settings, it is important to assess systematically how well they respond to the kind of challenges their classical counterparts have struggled with in the past two decades. The purpose of this paper is to study the behavior of deep learning systems in settings that have previously been deemed challenging to classical machine learning systems to find out whether the depth of the systems is an asset in such settings. The results in both artificial and real-world image datasets show that these settings remain mostly challenging for Deep Learning systems. Deeper architectures help with structural concept complexity but not with data scarcity and class overlap.

Paper Link: [click here](https://ieeexplore.ieee.org/abstract/document/9672056) 

Fighting Concept Complexity and Imbalance in Deep Models


ArtificialImg_ColinP1_C1_Train.py : Complexity 1

ArtificialImg_ColinP1_C2_Train.py : Complexity 2

ArtificialImg_ColinP1_C3_Train.py : Complexity 3

ArtificialImg_Colin_BackboneTrain.py : Following the Backbone
